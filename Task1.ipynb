{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "* First, we need to import the necessary libraries.\n",
    "* Then we load the configuration file.\n",
    "  * The config file contains information like the database config and the API key\n",
    "* Then we setup the SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from IPython.display import JSON\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import configparser as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Reads the config file and returns the config object\n",
    "\"\"\"\n",
    "config = cp.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite\n",
    "\n",
    "I decided to user a SQLite database instead of simply keeping the data in memory or in a JSON file, not just because of the size of the dataset, but also because of the inherent structure of the data itself.\n",
    "\n",
    "As it is to be expected that the the n to n relationship between the Repos and the Contributors will be queried a lot, so it makes more sense to have a database which can handle relational requests, instead of manually joining dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(config['DB']['NAME'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up the Queries\n",
    "\n",
    "Due to Githubs limitation on the number of 1000 items returned per query\\[1\\] we need to create queries which get less than 1000 items, but still cover the entirety of the dataset.\n",
    "\n",
    "Previous attempts\\[2\\] to solve this exact problem constrained their queries by the amount of stars for each repository.\n",
    "A method, which only works as long a there are less than 1000 repositories with the same amount of stars.\n",
    "\n",
    "This was then mitigated by using the creation date of the repository as a second constraint.\n",
    "As described in their corresponding blog article \\[3\\], this solution works by:\n",
    "\n",
    "* First querying the Github Graphql API to see the result count of how many items a given query would provide\n",
    "* If it is above a count of 1000 results the takes the date of jungest and oldest repository and splits the query in half of the time range\n",
    "* Then the size of these two queries is checked again and if they are still above 1000 results the process is repeated until the size of the queries is below 1000 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to convert a Unix timestamp to a string in the format required by the github api\n",
    "to_string = lambda stamp : datetime.fromtimestamp(stamp).strftime('%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2007-01-01T00:00:00Z to 2008-01-05T08:35:07Z. Progress: 0.00%\n",
      "Working on 2008-01-05T08:35:07Z to 2008-04-06T17:43:53Z. Progress: 0.03%\n",
      "Working on 2008-04-06T17:43:53Z to 2008-07-08T01:52:40Z. Progress: 0.12%\n",
      "Working on 2008-07-08T01:52:40Z to 2008-08-23T05:57:03Z. Progress: 0.16%\n",
      "Working on 2008-08-23T05:57:03Z to 2008-10-08T10:01:27Z. Progress: 0.20%\n",
      "Working on 2008-10-08T10:01:27Z to 2008-11-23T13:05:50Z. Progress: 0.26%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m end \u001b[39m=\u001b[39m \u001b[39m1678209714\u001b[39m  \u001b[39m# Current Time stamp (for consistency will not use time.time()\u001b[39;00m\n\u001b[1;32m     58\u001b[0m amount_of_repos \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m split_querys(start, end)\n",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# If the number of repos in the repos in the time range is greater than 1000\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     31\u001b[0m   split_querys((start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# If the number of repos in the repos in the time range is greater than 1000\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     31\u001b[0m   split_querys((start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# If the number of repos in the repos in the time range is greater than 1000\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     31\u001b[0m   split_querys((start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[1;32m     30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m   split_querys((start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   sections\u001b[39m.\u001b[39mappend((start, end))\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[1;32m     30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m   split_querys((start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   sections\u001b[39m.\u001b[39mappend((start, end))\n",
      "    \u001b[0;31m[... skipping similar frames: split_querys at line 31 (1 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrepositoryCount\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m     28\u001b[0m   \u001b[39m# We split the range in half and do the same query on each half\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[39m# This will continue recursively until the number of repos is less than 1000\u001b[39;00m\n\u001b[1;32m     30\u001b[0m   split_querys(start, (start \u001b[39m+\u001b[39m end)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m   split_querys((start \u001b[39m+\u001b[39;49m end)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, end) \n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m   \u001b[39m# If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m   sections\u001b[39m.\u001b[39mappend((start, end))\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36msplit_querys\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mglobal\u001b[39;00m amount_of_repos\n\u001b[1;32m      3\u001b[0m \u001b[39mglobal\u001b[39;00m repos_done\n\u001b[0;32m----> 5\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m      6\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttps://api.github.com/graphql\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m         headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mAuthorization\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mbearer \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m config[\u001b[39m'\u001b[39;49m\u001b[39mAPI\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mKEY\u001b[39;49m\u001b[39m'\u001b[39;49m]},\n\u001b[1;32m      8\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: count_query \u001b[39m%\u001b[39;49m (to_string(start), to_string(end))}\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[39m# On the first run we get the total number of repos \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# This is used to calculate the progress of the script\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m (amount_of_repos \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:117\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def split_querys(start, end):\n",
    "  global amount_of_repos\n",
    "  global repos_done\n",
    "\n",
    "  repo_count_response = requests.post(\n",
    "          'https://api.github.com/graphql',\n",
    "          headers={'Authorization': 'bearer '+ config['API']['KEY']},\n",
    "          json={\"query\": count_query % (to_string(start), to_string(end))}\n",
    "      )\n",
    "  \n",
    "  # On the first run we get the total number of repos \n",
    "  # This is used to calculate the progress of the script\n",
    "  if (amount_of_repos is None):\n",
    "    amount_of_repos = repo_count_response.json()[\"data\"][\"search\"][\"repositoryCount\"]\n",
    "    repos_done = 0\n",
    "\n",
    "  # If we are close to the rate limit we sleep until the rate limit resets\n",
    "  if repo_count_response.json()[\"data\"][\"rateLimit\"][\"remaining\"] < 10:\n",
    "    reset_time = datetime.strptime( repo_count_response.json()[\"data\"][\"rateLimit\"][\"resetAt\"], '%Y-%m-%dT%H:%M:%SZ')\n",
    "    \n",
    "    while datetime.now() < reset_time:\n",
    "      seconds_till_reset = (reset_time - datetime.now()).total_seconds()\n",
    "      print (\"Sleeping till %s... %d minutes and %d seconds left...\" % ( reset_time, *divmod(seconds_till_reset, 60)))\n",
    "      time.sleep(5)\n",
    "\n",
    "  # If the number of repos in the repos in the time range is greater than 1000\n",
    "  if repo_count_response.json()[\"data\"][\"search\"][\"repositoryCount\"] > 1000:\n",
    "    # We split the range in half and do the same query on each half\n",
    "    # This will continue recursively until the number of repos is less than 1000\n",
    "    split_querys(start, (start + end)//2)\n",
    "    split_querys((start + end)//2, end) \n",
    "    \n",
    "  else:\n",
    "    # If we finnaly get a range with less than 1000 repos we add the timestamps to the sections list\n",
    "    sections.append((start, end))\n",
    "    repos_done = repos_done+repo_count_response.json()[\"data\"][\"search\"][\"repositoryCount\"]\n",
    "    print(f\"Working on {to_string(start)} to {to_string(end)}. Progress: {repos_done/amount_of_repos*100:.2f}%\")\n",
    "    \n",
    "# The query to get the number of repos in a given time range as well as the current state of the rate limit\n",
    "count_query = ''' query { \n",
    "                   rateLimit {\n",
    "                    cost\n",
    "                    remaining\n",
    "                    resetAt\n",
    "                  }\n",
    "                  search(\n",
    "                    query:\"is:public, stars:>15, created:%s..%s\"\n",
    "                    type: REPOSITORY, first: 1) {\n",
    "                    repositoryCount\n",
    "                  }\n",
    "                } '''\n",
    "\n",
    "sections = []\n",
    "\n",
    "start = 1167609600 # Timestamp for 2007-01-01 (Github was founded in 2008 so this will cover all repos)\n",
    "end = 1678209714  # Current Time stamp (for consistency will not use time.time()\n",
    "\n",
    "amount_of_repos = None\n",
    "\n",
    "split_querys(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = pickle.load(open(\"sections.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 1/1235319 repos. Progress: 0.00%.\n",
      "{'hasNextPage': False, 'endCursor': 'Y3Vyc29yOjE='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 101/1235319 repos. Progress: 0.01%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjEwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 201/1235319 repos. Progress: 0.02%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjIwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 301/1235319 repos. Progress: 0.02%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjMwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 401/1235319 repos. Progress: 0.03%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjQwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 424/1235319 repos. Progress: 0.03%.\n",
      "{'hasNextPage': False, 'endCursor': 'Y3Vyc29yOjQyMw=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 524/1235319 repos. Progress: 0.04%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjEwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 624/1235319 repos. Progress: 0.05%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjIwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 724/1235319 repos. Progress: 0.06%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjMwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Downloading 824/1235319 repos. Progress: 0.07%.\n",
      "{'hasNextPage': True, 'endCursor': 'Y3Vyc29yOjQwMA=='}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[39mprint\u001b[39m( repo_query_response\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msearch\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mpageInfo\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m section \u001b[39min\u001b[39;00m sections:\n\u001b[0;32m---> 87\u001b[0m   download_repos(section[\u001b[39m0\u001b[39;49m], section[\u001b[39m1\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[81], line 64\u001b[0m, in \u001b[0;36mdownload_repos\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mwhile\u001b[39;00m (has_next_page):\n\u001b[1;32m     62\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m   repo_query_response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m     65\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mhttps://api.github.com/graphql\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     66\u001b[0m             headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mAuthorization\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mbearer \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m config[\u001b[39m'\u001b[39;49m\u001b[39mAPI\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mKEY\u001b[39;49m\u001b[39m'\u001b[39;49m]},\n\u001b[1;32m     67\u001b[0m             json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: repo_query \u001b[39m%\u001b[39;49m (to_string(start), to_string(end), \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mafter: \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mcursor\u001b[39m}\u001b[39;49;00m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m cursor \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m )}\n\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m   \u001b[39m# If we are close to the rate limit we sleep until the rate limit resets\u001b[39;00m\n\u001b[1;32m     70\u001b[0m   \u001b[39mif\u001b[39;00m repo_query_response\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mrateLimit\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mremaining\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:117\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "repos_downloaded = 0\n",
    "nodes = []\n",
    "\n",
    "\n",
    "def download_repos (start, end):\n",
    "  global repos_downloaded\n",
    "  global nodes\n",
    "  cursor = None\n",
    "  has_next_page = True\n",
    "\n",
    "  repo_query= \"\"\"\n",
    "                {\n",
    "                  rateLimit {\n",
    "                    cost\n",
    "                    remaining\n",
    "                    resetAt\n",
    "                  }\n",
    "                  search(\n",
    "                    query: \"is:public, stars:>15, created:%s..%s\"\n",
    "                    %s\n",
    "                    type: REPOSITORY\n",
    "                    first: 100\n",
    "                  ) {\n",
    "                    repositoryCount\n",
    "                    pageInfo {\n",
    "                      hasNextPage\n",
    "                      endCursor\n",
    "                    }\n",
    "                    edges {\n",
    "                      node {\n",
    "                        ... on Repository {\n",
    "                          createdAt\n",
    "                          forkCount\n",
    "                          isFork\n",
    "                          updatedAt\n",
    "                          primaryLanguage {\n",
    "                            name\n",
    "                          }\n",
    "                          watchers {\n",
    "                            totalCount\n",
    "                          }\n",
    "                          stargazerCount\n",
    "                          databaseId\n",
    "                          owner {\n",
    "                            id\n",
    "                            ... on User {\n",
    "                              id\n",
    "                              createdAt\n",
    "                              databaseId\n",
    "                              name\n",
    "                            }\n",
    "                          }\n",
    "                          id\n",
    "                          name\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                  }\n",
    "                }\"\"\"\n",
    "\n",
    "  while (has_next_page):\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    repo_query_response = requests.post(\n",
    "              'https://api.github.com/graphql',\n",
    "              headers={'Authorization': 'bearer '+ config['API']['KEY']},\n",
    "              json={\"query\": repo_query % (to_string(start), to_string(end), f\"after: \\\"{cursor}\\\"\" if cursor else \"\" )}\n",
    "          )\n",
    "    # If we are close to the rate limit we sleep until the rate limit resets\n",
    "    if repo_query_response.json()[\"data\"][\"rateLimit\"][\"remaining\"] < 10:\n",
    "      reset_time = datetime.strptime( repo_query_response.json()[\"data\"][\"rateLimit\"][\"resetAt\"], '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "      while datetime.now() < reset_time:\n",
    "        seconds_till_reset = (reset_time - datetime.now()).total_seconds()\n",
    "        print (\"Sleeping till %s... %d minutes and %d seconds left...\" % ( reset_time, *divmod(seconds_till_reset, 60)))\n",
    "        time.sleep(5)\n",
    "\n",
    "    repos_downloaded = repos_downloaded + len(repo_query_response.json()[\"data\"][\"search\"][\"edges\"])\n",
    "    cursor = repo_query_response.json()[\"data\"][\"search\"][\"pageInfo\"][\"endCursor\"]\n",
    "    has_next_page = repo_query_response.json()[\"data\"][\"search\"][\"pageInfo\"][\"hasNextPage\"]\n",
    "    nodes = nodes + repo_query_response.json()[\"data\"][\"search\"][\"edges\"]\n",
    "    \n",
    "    print(f\"Downloading {repos_downloaded}/{amount_of_repos} repos. Progress: {repos_downloaded/amount_of_repos*100:.2f}%.\")\n",
    "    print( repo_query_response.json()[\"data\"][\"search\"][\"pageInfo\"])\n",
    "\n",
    "for section in sections:\n",
    "  download_repos(section[0], section[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584556174\n",
      "582970339\n",
      "583706111\n",
      "583824425\n",
      "584522336\n",
      "584351443\n",
      "583172165\n",
      "583488732\n",
      "584477080\n",
      "583999445\n",
      "583450891\n",
      "583085674\n",
      "584443067\n",
      "584591805\n",
      "583772808\n",
      "583430700\n",
      "583047772\n",
      "583665827\n",
      "583824526\n",
      "584429431\n",
      "583335116\n",
      "584262559\n",
      "583615061\n",
      "583765500\n",
      "583704527\n",
      "583954357\n",
      "583616027\n",
      "584017827\n",
      "583809866\n",
      "584131216\n",
      "584165139\n",
      "584547922\n",
      "583057559\n",
      "584502403\n",
      "584051226\n",
      "584622314\n",
      "583459605\n",
      "583369920\n",
      "584630595\n",
      "583174341\n",
      "584105200\n",
      "583537416\n",
      "583803874\n",
      "584363621\n",
      "583512692\n",
      "583375059\n",
      "584349473\n",
      "584189373\n",
      "583699147\n",
      "583375511\n",
      "583640426\n",
      "584022883\n",
      "582989161\n",
      "583386618\n",
      "584239673\n",
      "584145750\n",
      "583790421\n",
      "583773699\n",
      "583689551\n",
      "583315360\n",
      "583597081\n",
      "583738217\n",
      "583124988\n",
      "583331123\n",
      "583419398\n",
      "584580166\n",
      "583268270\n",
      "584574007\n",
      "583220952\n",
      "584521206\n",
      "584573194\n",
      "583024727\n",
      "583508796\n",
      "583079961\n",
      "584177219\n",
      "583835507\n",
      "583966597\n",
      "583446148\n",
      "583332730\n",
      "582969786\n",
      "584622033\n",
      "583935180\n",
      "584404380\n",
      "583942910\n",
      "584365872\n",
      "583624397\n",
      "584317678\n",
      "583500307\n",
      "584102226\n",
      "584125419\n",
      "584219588\n",
      "583927613\n",
      "584034634\n",
      "584370823\n",
      "583806262\n",
      "583476976\n",
      "583785011\n",
      "583059661\n",
      "584200680\n",
      "583409095\n",
      "584556174\n",
      "582970339\n",
      "583706111\n",
      "583824425\n",
      "584522336\n",
      "584351443\n",
      "583172165\n",
      "583488732\n",
      "584477080\n",
      "583999445\n",
      "583450891\n",
      "583085674\n",
      "584443067\n",
      "584591805\n",
      "583772808\n",
      "583430700\n",
      "583047772\n",
      "583665827\n",
      "583824526\n",
      "584429431\n",
      "583335116\n",
      "584262559\n",
      "583615061\n",
      "583765500\n",
      "583704527\n",
      "583954357\n",
      "583616027\n",
      "584017827\n",
      "583809866\n",
      "584131216\n",
      "584165139\n",
      "584547922\n",
      "583057559\n",
      "584502403\n",
      "584051226\n",
      "584622314\n",
      "583459605\n",
      "583369920\n",
      "584630595\n",
      "583174341\n",
      "584105200\n",
      "583537416\n",
      "583803874\n",
      "584363621\n",
      "583512692\n",
      "583375059\n",
      "584349473\n",
      "584189373\n",
      "583699147\n",
      "583375511\n",
      "583640426\n",
      "584022883\n",
      "582989161\n",
      "583386618\n",
      "584239673\n",
      "584145750\n",
      "583790421\n",
      "583773699\n",
      "583689551\n",
      "583315360\n",
      "583597081\n",
      "583738217\n",
      "583124988\n",
      "583331123\n",
      "583419398\n",
      "584580166\n",
      "583268270\n",
      "584574007\n",
      "583220952\n",
      "584521206\n",
      "584573194\n",
      "583024727\n",
      "583508796\n",
      "583079961\n",
      "584177219\n",
      "583835507\n",
      "583966597\n",
      "583446148\n",
      "583332730\n",
      "582969786\n",
      "584622033\n",
      "583935180\n",
      "583942910\n",
      "584404380\n",
      "584365872\n",
      "583624397\n",
      "584317678\n",
      "583500307\n",
      "584102226\n",
      "584125419\n",
      "584219588\n",
      "583927613\n",
      "584034634\n",
      "584370823\n",
      "583806262\n",
      "583476976\n",
      "583785011\n",
      "583059661\n",
      "584200680\n",
      "583409095\n",
      "584556174\n",
      "582970339\n",
      "583706111\n",
      "583824425\n",
      "584522336\n",
      "584351443\n",
      "583172165\n",
      "583488732\n",
      "584477080\n",
      "583999445\n",
      "583450891\n",
      "583085674\n",
      "584443067\n",
      "584591805\n",
      "583772808\n",
      "583430700\n",
      "583047772\n",
      "583665827\n",
      "583824526\n",
      "584429431\n",
      "583335116\n",
      "584262559\n",
      "583615061\n",
      "583765500\n",
      "583704527\n",
      "583954357\n",
      "583616027\n",
      "584017827\n",
      "583809866\n",
      "584131216\n",
      "584165139\n",
      "584547922\n",
      "583057559\n",
      "584502403\n",
      "584051226\n",
      "584622314\n",
      "583459605\n",
      "583369920\n",
      "584630595\n",
      "583174341\n",
      "584105200\n",
      "583537416\n",
      "583803874\n",
      "584363621\n",
      "583512692\n",
      "583375059\n",
      "584349473\n",
      "584189373\n",
      "583699147\n",
      "583375511\n",
      "583640426\n",
      "584022883\n",
      "582989161\n",
      "583386618\n",
      "584239673\n",
      "584145750\n",
      "583790421\n",
      "583773699\n",
      "583689551\n",
      "583315360\n",
      "583597081\n",
      "583738217\n",
      "583124988\n",
      "583331123\n",
      "583419398\n",
      "584580166\n",
      "583268270\n",
      "584574007\n",
      "583220952\n",
      "584521206\n",
      "584573194\n",
      "583024727\n",
      "583508796\n",
      "583079961\n",
      "584177219\n",
      "583835507\n",
      "583966597\n",
      "583446148\n",
      "583332730\n",
      "582969786\n",
      "584622033\n",
      "583935180\n",
      "583942910\n",
      "584404380\n",
      "584365872\n",
      "583624397\n",
      "584317678\n",
      "583500307\n",
      "584102226\n",
      "584125419\n",
      "584219588\n",
      "583927613\n",
      "584034634\n",
      "584370823\n",
      "583806262\n",
      "583476976\n",
      "583785011\n",
      "583059661\n",
      "584200680\n",
      "583409095\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node[\"node\"][\"databaseId\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "[1] Resources in the REST API, GitHub Docs. https://docs.github.com/en/rest/overview/resources-in-the-rest-api?apiVersion=2022-11-28 (accessed Mar. 07, 2023).\n",
    "\n",
    "[2] danvk, How can I get a list of all public GitHub repos with more than 20 stars?, Stack Overflow, Feb. 02, 2020. https://stackoverflow.com/q/60022429 (accessed Mar. 07, 2023).\n",
    "\n",
    "\n",
    "[3] D. Vanderkam, GitHub Stars and the h-index: A Journey, Medium, Feb. 10, 2020. https://danvdk.medium.com/github-stars-and-the-h-index-a-journey-c104cfe37da6 (accessed Mar. 06, 2023)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
